# EMG Signal Experiments Repository

A modular log and experiments for EMG signal analysis, gesture classification, and wearable robotics development. Designed as a knowledge base for research and skill-building.

## Struktur
- [`01_raw-data/`](01_raw-data/): Documentation of hardware, signal types, and gestures. 
- [`02_preprocessing/`](02_preprocessing/): Filtering and segmentation techniques.
- [`03_feature-extraction/`](03_feature-extraction/): Time-, frequency-, and hybrid-feature approaches.
- [`04_models/`](04_models/): ML and DL algorithms for EMG classification.
- [`05_results-analysis/`](05_results-analysis): Evaluation dan experimental insight.
- [`references/`](references/): Summaries of papers and literature sources.
- [`roadmap.md`](roadmap.md): Development plan and milestones.

## Status
🚧 This repo is currently in a personal exploration and development stage.

---

## 🧭 Experiment Navigation

| Category             | Deep-Dive Experiment       | Status | Link |
|----------------------|----------------------------|--------|------|
| Preprocessing        | Median vs Notch Filtering  | ✅      | [Repo](https://github.com/username/emg-preprocessing-benchmark) |
| Feature Extraction   | WL vs RMS Comparison       | ✅      | [Repo](https://github.com/username/emg-wl-vs-rms-comparison) |
| Model Evaluation     | CNN vs LSTM Classification | ⏳      | [Repo](https://github.com/username/cnn-emg-gesture-classification) |

> 📌 Each deep-dive experiment is hosted in a separate repository and linked from here.

---

## 🧪 Purpose & Philosophy

This repository is designed to:
- Explore and replicate EMG signal processing techniques from literature
- Build practical understanding through experimentation
- Document personal insights to support future research in wearable robotics

> *“Learning by doing, documenting by reflecting.”*

---

## 🧠 Personal Insights

Each experiment includes reflective notes such as:
- What did I learn?
- What didn’t work?
- How does this relate to my research goals?

Example:
> *“RMS features showed more stability under noisy conditions, while WL was more sensitive to gesture transitions.”*

---

## 🛠️ Tools & Technologies

- Python, NumPy, SciPy, scikit-learn, PyTorch
- GitHub CLI, VS Code, GitHub Actions
- Fusion360 (for wearable device design)
- Notion & GitHub Projects (for experiment tracking)

---

## 🏷️ Badges & Metadata

![License](https://img.shields.io/badge/license-MIT-blue)
![Status](https://img.shields.io/badge/status-experimental-orange)
![Last Updated](https://img.shields.io/github/last-commit/username/emg-signal-exp)
![Research Area](https://img.shields.io/badge/domain-EMG%20%26%20Wearable%20Robotics-green)

---

## 📚 References

Summaries of key papers and literature are available in the `references/` folder.  
Each experiment includes citations and theoretical background.

---

## 🚀 Roadmap

See `roadmap.md` for current milestones:
- [x] Modular repo structure setup
- [x] Preprocessing benchmark experiments
- [ ] Hybrid feature extraction trials
- [ ] Multi-channel gesture classification models

---

## 🤝 Collaboration & Contribution

This repository is exploratory and open to discussion.  
Feel free to open an issue or submit a pull request to share insights or improvements.

---

## 📬 About Me
I'm Angga Rahagiyanto, a PhD student specializing in intelligent systems.  
My research focuses on EMG signal processing, wearable robotics, and multidisciplinary skill development.

🔗 [GitHub Profile](https://github.com/rahagiyanto)  
🔗 [Portfolio Website](https://rahagiyanto.github.io)
